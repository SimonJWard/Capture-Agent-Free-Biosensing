{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12d18a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensionality reduction: None\n",
      "******************************\n",
      "Support Vector Machines:\n",
      "    linear kernel accuracy: 0.98\n",
      "    rbf kernel accuracy: 0.94\n",
      "    sigmoid kernel accuracy: 0.55\n",
      "    poly kernel accuracy: 0.98\n",
      "Random Forest accuracy: 0.99\n",
      "Logistic Regression accuracy: 0.96\n",
      "KNN accuracy: 0.92\n",
      "\n",
      "dimensionality reduction: PCA\n",
      "******************************\n",
      "Support Vector Machines:\n",
      "    linear kernel accuracy: 0.98\n",
      "    rbf kernel accuracy: 0.96\n",
      "    sigmoid kernel accuracy: 0.5\n",
      "    poly kernel accuracy: 0.92\n",
      "Random Forest accuracy: 0.9\n",
      "Logistic Regression accuracy: 0.94\n",
      "KNN accuracy: 0.94\n",
      "\n",
      "dimensionality reduction: LDA\n",
      "******************************\n",
      "Support Vector Machines:\n",
      "    linear kernel accuracy: 1.0\n",
      "    rbf kernel accuracy: 0.98\n",
      "    sigmoid kernel accuracy: 0.51\n",
      "    poly kernel accuracy: 0.99\n",
      "Random Forest accuracy: 0.94\n",
      "Logistic Regression accuracy: 0.9\n",
      "KNN accuracy: 0.92\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "data_file_path = \"../TrainingData/SensorArrayProteinResponseMatrixPairwiseAveraging.csv\"\n",
    "\n",
    "# features:\n",
    "#   - current density used to fabricate sensors, correlated with pore size {55mAcm^-2, 40mAcm^-2, 25mAcm^-2}\n",
    "#   - pH of buffer used to make protein solutions {pH4, pH10}\n",
    "features = ['55mAcm^-2pH4','55mAcm^-2pH10','40mAcm^-2pH4','40mAcm^-2pH10','25mAcm^-2pH4','25mAcm^-2pH10']\n",
    "\n",
    "# load dataset into Pandas DataFrame\n",
    "df = pd.read_csv(data_file_path, header=0)\n",
    "\n",
    "# load data and labels\n",
    "x = df.loc[:, features].values\n",
    "y = df.loc[:,['Labels']].values\n",
    "\n",
    "# dimensionality reduction\n",
    "dim_red = ['None', 'PCA', 'LDA']\n",
    "\n",
    "# loop over different methods of dimensionality reduction preprocessing\n",
    "for preprocessing in dim_red:\n",
    "    \n",
    "    models = [SVC(kernel='linear', C=200)\n",
    "              , SVC(kernel='rbf', C=200)\n",
    "              , SVC(kernel='sigmoid', C=200)\n",
    "              , SVC(kernel='poly', C=200)\n",
    "              , RandomForestClassifier(n_estimators = 100)\n",
    "              , LogisticRegression(max_iter=10000, solver='saga', penalty='l1', C=10)\n",
    "              , KNeighborsClassifier(n_neighbors=7)]\n",
    "    \n",
    "    models_accuracy = np.zeros(len(models),)\n",
    "    \n",
    "    SVM_linear_kernel_accuracy = 0\n",
    "    SVM_rbf_kernel_accuracy = 0\n",
    "    SVM_sigmoid_kernel_accuracy = 0\n",
    "    SVM_poly_kernel_accuracy = 0\n",
    "    LRaccuracy = 0\n",
    "    RFaccuracy = 0\n",
    "    KNNaccuracy = 0\n",
    "    \n",
    "    print(f'dimensionality reduction: {preprocessing}')\n",
    "    print('******************************')\n",
    "    \n",
    "    for example in range(len(x)):\n",
    "        \n",
    "        # create boolean array mask the same shape as the first column of x with\n",
    "        # all elements initialized as False, except the row corresponding to the\n",
    "        # 6D sensor array response which is the test set for\n",
    "        # leave-one-out cross validation (and vice versa for the training set)\n",
    "        indices_test = (x[:,0]*0).astype('bool')\n",
    "        indices_test[example] = True\n",
    "        indices_train = [not element for element in indices_test]\n",
    "        \n",
    "        # train/test splits\n",
    "        x_train = x[indices_train]\n",
    "        x_test = x[indices_test]\n",
    "        y_train = y[indices_train]\n",
    "        y_test = y[indices_test]\n",
    "        y_train = np.transpose(y_train)[0,]\n",
    "        y_test = np.transpose(y_test)[0,]\n",
    "        \n",
    "        # standardize the data using mean and stdev from training data\n",
    "        Scaler = StandardScaler()\n",
    "        Scaler.fit(x_train)\n",
    "        x_train = Scaler.transform(x_train)\n",
    "        x_test = Scaler.transform(x_test)\n",
    "        \n",
    "        # apply dimenionsality reduction\n",
    "        # LDA\n",
    "        if preprocessing == 'LDA':\n",
    "            modelLDA = LinearDiscriminantAnalysis(n_components=3, tol=1e-3, solver = 'svd')\n",
    "            modelLDA.fit(x_train, y_train)\n",
    "            x_test = modelLDA.transform(x_test)\n",
    "            x_train = modelLDA.transform(x_train)\n",
    "        \n",
    "        # PCA\n",
    "        if preprocessing == 'PCA':\n",
    "            modelPCA = PCA(n_components=3)\n",
    "            modelPCA.fit(x_train)\n",
    "            x_test = modelPCA.transform(x_test)\n",
    "            x_train = modelPCA.transform(x_train)\n",
    "        \n",
    "        \n",
    "        #train models on training data\n",
    "        trained_models = [model.fit(x_train, y_train) for model in models]\n",
    "        \n",
    "        #evaluate models on test data\n",
    "        models_accuracy += np.array([trained_model.score(x_test, y_test) for trained_model in trained_models])\n",
    "    \n",
    "    models_accuracy /= len(x)\n",
    "    print('Support Vector Machines:')\n",
    "    print(f'    linear kernel accuracy: {round(models_accuracy[0],2)}')\n",
    "    print(f'    rbf kernel accuracy: {round(models_accuracy[1],2)}')\n",
    "    print(f'    sigmoid kernel accuracy: {round(models_accuracy[2],2)}')\n",
    "    print(f'    poly kernel accuracy: {round(models_accuracy[3],2)}')    \n",
    "    print(f'Random Forest accuracy: {round(models_accuracy[4],2)}')   \n",
    "    print(f'Logistic Regression accuracy: {round(models_accuracy[5],2)}')\n",
    "    print(f'KNN accuracy: {round(models_accuracy[6],2)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cef9e18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
